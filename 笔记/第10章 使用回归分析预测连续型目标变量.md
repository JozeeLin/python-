# 第10章 使用回归分析预测连续型目标变量

本章将进入监督学习的另一个分支:回归分析。回归模型可用于连续型目标变量的预测分析，这使得它在探寻变量间关系、评估趋势、做出预测等科学及工业领域应用中极具吸引力。例如，预测公司在未来几个月的销售情况等。

在本章，我们将介绍回归模型的主要概念，将涵盖如下主题:

- 数据集的探索和可视化
- 实现线性回归模型的不同方法
- 训练可处理异常值的回归模型
- 回归模型的评估及常见问题
- 基于非线性数据拟合回归模型

## 简单线性回归模型初探

简单线性回归的目标是:通过模型来描述某一特征(解释变量x)与连续输出(目标变量y)之间的关系。当只有一个解释变量时，线性模型的函数定义如下:
$$
y = w_0 + w_1x
$$
其中，权值$w_0$为函数在y轴上的截距，$w_1$为解释变量的系数。我们的目标是通过学习得到线性方程的这两个权值，并用它们描述解释变量与目标变量之间的关系，当解释变量为非训练数据集中数据时，可用此线性关系来预测对应的输出。

基于前面所定义的线性方程，线性回归可看作是求解样本点的最佳拟合直线。这条最佳拟合线也被称为**回归线**。回归线与样本点之间的垂直连线即所谓的**偏移(offset)或残差(residual)**——预测的误差。

一元线性回归也称为简单线性回归。

多元线性回归的表达式为:
$$
y = w_0x_0+w_1x_1+w_2x_2+\dots+w_mx_m=\sum_{i=0}^{n}w_ix_i = W^TX
$$
其中，$w_0$为$x_0=1$时在y轴上的截距。

## 波士顿房屋数据集

数据集下载:https://archive.ics.uci.edu/ml/datasets/Housing

## 探索性数据分析(Exploratory Data Analysis,EDA)

> 注意:不同于人们通常的理解，训练一个线性回归模型并不需要解释数量或者目标变量呈高斯分布。正态假设仅适用于某些统计检验和假设检验。

使用相关系数矩阵来量化特征之间的相关性。我们可以把相关系数矩阵看作协方差矩阵的标准化版本。实际上，相关系数矩阵就是在将数据标准化后得到的协方差矩阵。

相关系数矩阵是一个包含皮尔逊积矩相关系数(Pearson product-monment correlation coefficient,通常记为Pearson's r)的方阵，它用来衡量两两特征间的线性依赖关系。
$$
r = \frac{\sum_{i=1}^{n}[(x^i-\mu_x)(y^i-\mu_y)]}{\sqrt{\sum_{i=1}^{n}(x^i-\mu_x)^2}\sqrt{\sum_{i=1}^{n}(y^i-\mu_y)^2}} = \frac{\sigma_{xy}}{\sigma_x\sigma_y}
$$
其中，$\mu$为样本对应特征的均值，$\sigma_{xy}$为特征x和y间的协方差，而$\sigma_x$和$\sigma_y$分别为两个特征的标准差。

证明:经标准化各特征间的协方差实际上等价于它们的线性相关系数。

**证明:**
$$
x^{'} = \frac{x-\mu_x}{\sigma_x},y^{'}=\frac{y-\mu_y}{\sigma_y}
$$
两个特征间的协方差:
$$
\sigma_{xy} = \frac{1}{n}\sum_{i}^{n}[(x^i-\mu_x)(y^i-\mu_y)]
$$
由于对特征进行标准化之后，均值都为0，所以最终可得到:
$$
\sigma^{'}_{xy} = \frac{\sigma_{xy}}{\sigma_x\sigma_y}
$$
我们可以通过numpy的corrcoef函数计算前面散点图矩阵中5个特征间的相关系数矩阵。并使用seaborn的heatmap函数绘制其对应的热度图。

